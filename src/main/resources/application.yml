spring:
  application:
    name: resume-analyzer
  
  datasource:
    url: jdbc:postgresql://localhost:5432/resume_analyzer
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:postgres}
    driver-class-name: org.postgresql.Driver
  
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        jdbc:
          lob:
            non_contextual_creation: true
  
  servlet:
    multipart:
      enabled: true
      max-file-size: 50MB
      max-request-size: 100MB
  
  graphql:
    graphiql:
      enabled: true
      path: /graphiql
    path: /graphql
    schema:
      printer:
        enabled: true
  
  ai:
    openai:
      base-url: ${LLM_STUDIO_BASE_URL:http://localhost:1234/v1}
      api-key: ${LLM_STUDIO_API_KEY:not-needed}
      chat:
        options:
          model: ${LLM_STUDIO_MODEL:mistralai/mistral-7b-instruct-v0.3}
          temperature: 0.7
          max-tokens: 4000
      embedding:
        options:
          model: ${LLM_STUDIO_EMBEDDING_MODEL:text-embedding-nomic-embed-text-v1.5}

# JWT Configuration
jwt:
  secret: ${JWT_SECRET:YourSecretKeyMustBeAtLeast256BitsLongForHS256AlgorithmToWorkProperlyPleaseChangeThisInProduction}
  access-token-expiration-ms: ${JWT_ACCESS_TOKEN_EXPIRATION:900000}  # 15 minutes
  refresh-token-expiration-ms: ${JWT_REFRESH_TOKEN_EXPIRATION:604800000}  # 7 days

# Application AI Configuration
ai:
  llm:
    timeout: 120000
    retry-attempts: 3

# Application Configuration
app:
  upload:
    directory: ${UPLOAD_DIR:./uploads}
    allowed-extensions: .doc,.docx,.pdf
  
  embedding:
    dimension: 768
    batch-size: 10
  
  processing:
    thread-pool-size: 5
    max-retries: 3
  
  # Job Scheduler Configuration
  # Set scheduler.enabled=true to use queue-based processing
  # Set scheduler.enabled=false to use legacy async processing
  scheduler:
    enabled: ${SCHEDULER_ENABLED:false}  # Feature flag: true=scheduler, false=async
    poll-interval-ms: ${SCHEDULER_POLL_INTERVAL:5000}  # How often to check for jobs (5 seconds)
    initial-delay-ms: ${SCHEDULER_INITIAL_DELAY:10000}  # Wait before first poll (10 seconds)
    batch-size: ${SCHEDULER_BATCH_SIZE:5}  # Max jobs to claim per poll
    thread-pool-size: ${SCHEDULER_THREAD_POOL:5}  # Worker threads for job processing
    worker-id: ${SCHEDULER_WORKER_ID:worker-1}  # Unique ID for this worker instance
    stale-job-threshold-minutes: ${SCHEDULER_STALE_THRESHOLD:15}  # Jobs without heartbeat for 15 min = stale
    stale-check-interval-ms: ${SCHEDULER_STALE_CHECK_INTERVAL:60000}  # Check for stale jobs every minute
    stale-check-initial-delay-ms: ${SCHEDULER_STALE_CHECK_DELAY:30000}  # Wait 30s before first stale check
    cleanup-cron: ${SCHEDULER_CLEANUP_CRON:0 0 2 * * ?}  # Cleanup old jobs daily at 2 AM
    cleanup-retention-days: ${SCHEDULER_CLEANUP_RETENTION:30}  # Keep completed jobs for 30 days
    metrics-log-interval-ms: ${SCHEDULER_METRICS_INTERVAL:300000}  # Log metrics every 5 minutes

# Server Configuration
server:
  port: 8080
  compression:
    enabled: true
    mime-types: 
      - text/html
      - text/xml
      - text/plain
      - text/css
      - text/javascript
      - application/javascript
      - application/json
    min-response-size: 1024

# Logging Configuration
logging:
  level:
    io.subbu.ai.firedrill: DEBUG
    org.springframework.web: INFO
    org.hibernate: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/resume-analyzer.log
    max-size: 10MB
    max-history: 30

# Spring Boot Actuator Configuration
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
      base-path: /actuator
  endpoint:
    health:
      enabled: true
      show-details: when-authorized
      probes:
        enabled: true
  health:
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true
    db:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
  info:
    env:
      enabled: true
